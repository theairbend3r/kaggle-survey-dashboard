caches = list()
A = X
L = floor(length(parameters)/2)
A_prev <- A
for (i in 1:(L-1)) {
W <- paste("W", i, sep = "")
b <- paste("b", i, sep = "")
linear_activation_forward <- linearActivationForward(A_prev, parameters[[W]], parameters[[b]], activation = "relu")
A <- linear_activation_forward$A
cache <- linear_activation_forward$cache
caches <- append(caches, cache)
A_prev <- A
}
WL <- paste("W", L, sep = "")
bL <- paste("b", L, sep = "")
AL <- linearActivationForward(A_prev, parameters[[WL]], parameters[[bL]], activation = "sigmoid")$A
cache <- linearActivationForward(A_prev, parameters[[WL]], parameters[[bL]], activation = "sigmoid")$cache
caches <- append(caches, cache)
out <- list("AL" = AL,
"caches" = caches)
return (out)
}
L_model_forward <- LModelForward(X_train, params)
L_model_forward$caches
computeCost <- function(AL, y) {
m <- dim(y)[2]
logprobs <- (log(AL) * y) + (log(1-AL) * (1-y))
cost <- -sum(logprobs/m)
return (cost)
}
cost <- computeCost(L_model_forward$AL, y_train)
cost
relu_backward <- function(dA, cache){
Z <- cache
dZ <- as.matrix(dA)
dZ[Z <= 0] <- 0
return (dZ)
}
sigmoid_backward <- function(dA, cache) {
Z <- cache
s <- 1 / (1 + exp(-Z))
dZ <- as.matrix(dA * s * (1-s))
return (dZ)
}
linearBackward <- function(dZ, cache) {
A_prev <- cache$A
W <- cache$W
b <- cache$b
m <- dim(A_prev)[2]
dW <- 1/m * (dZ %*% t(A_prev))
db <- matrix(1/m * sum(dZ), nrow = dim(dW)[1])
dA_prev <- t(W) %*% dZ
out <- list("dA_prev" = dA_prev,
"dW" = dW,
"db" = db)
return (out)
}
dZ <- cost-y_train
linear_backward3 <- linearBackward(dZ, L_model_forward$caches[5]$linear_cache)
linear_backward2 <- linearBackward(linear_backward3$dA_prev, L_model_forward$caches[3]$linear_cache)
linear_backward1 <- linearBackward(linear_backward2$dA_prev, L_model_forward$caches[1]$linear_cache)
cat("dim dZ3: \n")
cat(dim(dZ), "\n\n")
cat("\nLinear Backward 3:\n ")
lapply(linear_backward3, function(x) dim(x))
cat("\nLinear Backward 2: \n")
lapply(linear_backward2, function(x) dim(x))
cat("\nLinear Backward 1: \n")
lapply(linear_backward1, function(x) dim(x))
linearActivationBackward <- function(dA, linear_cache, activation_cache, activation) {
if (activation == "relu") {
dZ <- relu_backward(dA, activation_cache)
}  else if (activation == "sigmoid") {
dZ <- sigmoid_backward(dA, activation_cache)
}
dA_prev <- linearBackward(dZ, linear_cache)$dA_prev
dW <- linearBackward(dZ, linear_cache)$dW
db <- linearBackward(dZ, linear_cache)$db
out <- list("dA_prev" = dA_prev,
"dW" = dW,
"db" = db)
return (out)
}
dA <- apply(X = dZ, MARGIN = c(1, 2), function(x) sigmoid(x)$A)
linear_activation_backward3 <- linearActivationBackward(dA = dA,
linear_cache = L_model_forward$caches[5]$linear_cache,
activation_cache = L_model_forward$caches[6]$activation_cache,
activation = "sigmoid")
linear_activation_backward2 <- linearActivationBackward(dA = linear_activation_backward3$dA_prev,
linear_cache = L_model_forward$caches[3]$linear_cache,
activation_cache = L_model_forward$caches[4]$activation_cache,
activation = "relu")
linear_activation_backward1 <- linearActivationBackward(dA = linear_activation_backward2$dA_prev,
linear_cache = L_model_forward$caches[1]$linear_cache,
activation_cache = L_model_forward$caches[2]$activation_cache,
activation = "relu")
cat("dim dA3: \n", dim(dA), "\n\n")
cat("\nLinear Backward 3:\n ")
lapply(linear_activation_backward3, function(x) dim(x))
cat("\nLinear Backward 2:\n ")
lapply(linear_activation_backward2, function(x) dim(x))
cat("\nLinear Backward 1:\n ")
lapply(linear_activation_backward1, function(x) dim(x))
LModelBackward <- function(AL, Y, caches) {
L <- length(caches) - 1
grads <- list()
m <- dim(AL)[2]
dA_L <- -((Y/AL) - ((1 - Y)/(1 - AL)))
current_linear_cache <- caches[L]$linear_cache
current_activation_cache <- caches[L+1]$activation_cache
linear_activation_backward_L <- linearActivationBackward(dA = dA_L,
linear_cache = current_linear_cache,
activation_cache = current_activation_cache,
activation = "sigmoid")
dAL <- paste("dA", floor(L/2)+1, sep="")
dWL <- paste("dW", floor(L/2)+1, sep="")
dbL <- paste("db", floor(L/2)+1, sep="")
grads[[dAL]] <- linear_activation_backward_L$dA_prev
grads[[dWL]] <- linear_activation_backward_L$dW
grads[[dbL]] <- linear_activation_backward_L$db
for (i in seq(L-2, 1, -2)) {
current_linear_cache <- caches[i]$linear_cache
current_activation_cache <- caches[i+1]$activation_cache
linear_activation_backward <- linearActivationBackward(dA = grads[[dAL]],
linear_cache = current_linear_cache,
activation_cache = current_activation_cache,
activation = "relu")
dA_prev_temp <- linear_activation_backward$dA_prev
dW_temp <- linear_activation_backward$dW
db_temp <- linear_activation_backward$db
dAL <- paste("dA", floor(i/2)+1, sep="")
dWL <- paste("dW", floor(i/2)+1, sep="")
dbL <- paste("db", floor(i/2)+1, sep="")
grads[[dAL]] <- dA_prev_temp
grads[[dWL]] <- dW_temp
grads[[dbL]] <- db_temp
}
return(grads)
}
L_model_backward<- LModelBackward(L_model_forward$AL, y_train, L_model_forward$caches)
L_model_backward
updateParameters <- function(parameters, grads, learning_rate){
L = floor(length(parameters)/2)
for (i in 1:L) {
W <- paste("W", i, sep="")
dW <- paste("dW", i, sep="")
b <- paste("b", i, sep="")
db <- paste("db", i, sep="")
parameters[[W]] <- parameters[[W]] - learning_rate * grads[[dW]]
parameters[[b]] <- parameters[[b]] - learning_rate * grads[[db]]
}
return (parameters)
}
update_params <- updateParameters(parameters = params, grads = L_model_backward, learning_rate = 0.1)
update_params
trainModel <- function(X, y, layer_size_list, iterations, learning_rate = 0.01) {
init_params <- initializeParameters(layer_size_list)
cost_history <- c()
for (i in 1:iterations) {
forward_pass <- LModelForward(X, init_params)
cost <- computeCost(forward_pass$AL, y)
backward_pass <- LModelBackward(forward_pass$AL, y, forward_pass$caches)
update_parameters <- updateParameters(init_params, backward_pass, learning_rate = learning_rate)
init_params <- update_parameters
cost_history <- c(cost_history, cost)
cat("Iteration", i, " | Cost: ", cost_history[i], "\n")
}
model_out <- list("updated_params" = update_parameters,
"cost_hist" = cost_history)
return (model_out)
}
train_model <- trainModel(X_train, y_train, list(2, 4, 3, 1), 20, 0.01)
makePrediction <- function(X, layer_size_list){
init_params <- initializeParameters(layer_size_list)
forward_pass <- LModelForward(X, init_params)
pred <- forward_pass$AL
return (pred)
}
y_pred <- makePrediction(X_test, list(2, 3, 4, 1))
y_pred <- round(y_pred)
y_pred
y_test
tb <- table(y_test, y_pred)
tb
acc <- (tb[1] + tb[4])/sum(tb)
cat("We are getting an accuracy of", acc*100, "%.")
library(ggplot2)
library(dplyr)
iris <- read.csv("../../data/iris2feat_2class.csv")
iris
test <- read.csv("../../data/iris2feat_2class_test.csv")
test
iris %>%
ggplot(mapping = aes(x = Sepal.Length, y= Sepal.Width)) + geom_point(aes(col = Species))
X_train <- iris %>%
select(Sepal.Length, Sepal.Width) %>%
mutate_all(function(x) scale(x))
y_train <- iris %>%
select(Species)
X_test <- test %>%
select(Sepal.Length, Sepal.Width) %>%
mutate_all(function(x) scale(x))
y_test <- test %>%
select(Species)
cat("Shape of X (row, column): \n", dim(X_train), "\nShape of y (row, column) : \n", dim(y_train), "\nNumber of training samples: \n", dim(X_train)[1], "\nShape of X_test (row, column): \n", dim(X_test), "\nShape of y_test (row, column) : \n", dim(y_test), "\nNumber of testing samples: \n", dim(X_test)[1])
X_train <- as.matrix(X_train, byrow=TRUE)
X_train <- t(X_train)
y_train <- as.matrix(y_train, byrow=TRUE)
y_train <- t(y_train)
X_test <- as.matrix(X_test, byrow=TRUE)
X_test <- t(X_test)
y_test <- as.matrix(y_test, byrow=TRUE)
y_test <- t(y_test)
initializeParametersShallow <- function(n_x, n_h, n_y){
W1 <- matrix(runif(n_h * n_x), nrow = n_h, ncol = n_x, byrow = TRUE)
b1 <- matrix(rep(0, n_h), nrow = n_h, ncol = 1)
W2 <- matrix(runif(n_y * n_h), nrow = n_y, ncol = n_h, byrow = TRUE)
b2 <- matrix(rep(0, n_y), nrow = n_y, ncol = 1)
params <- list("W1" = W1,
"b1" = b1,
"W2" = W2,
"b2" = b2)
return (params)
}
params_shallow <- initializeParametersShallow(2, 4, 1)
lapply(params_shallow, function(x) dim(x))
initializeParameters <- function(layer_dims){
L = length(layer_dims)
params <- list()
for (i in 2:L) {
w <- paste("W", i-1, sep="")
w_mat <- matrix(runif(layer_dims[[i]] * layer_dims[[i-1]]), nrow = layer_dims[[i]], ncol = layer_dims[[i-1]], byrow = TRUE)
params[[w]] <- w_mat
b <- paste("b", i-1, sep="")
b_mat <- matrix(rep(0, layer_dims[[i]]), nrow = layer_dims[[i]], byrow = TRUE)
params[[b]] <- b_mat
}
return (params)
}
params <- initializeParameters(list(2, 3, 4, 1))
lapply(params, function(x) dim(x))
sigmoid <- function(Z){
A <- 1 / (1 + exp(-Z))
cache <- Z
out <- list("A" = A,
"cache" = cache)
return (out)
}
relu <- function(Z){
if (Z >= 0) {
A <- Z
cache <- Z
out <- list("A" = A,
"cache" = cache)
return (out)
}
else {
A <- 0
cache <- Z
out <- list("A" = A,
"cache" = cache)
return (out)
}
}
linearForward <- function(A, W, b) {
m <- dim(A)[2]
b_new <- matrix(rep(b, m), nrow = dim(W)[1])
Z <- W %*% A + b_new
cache <- list("A" = A,
"W" = W,
"b" = b)
out <- list("Z" = Z,
"cache" = cache)
return (out)
}
linear_forward1 <- linearForward(X_train, params$W1, params$b1)
linear_forward2 <- linearForward(linear_forward1$Z, params$W2, params$b2)
linear_forward3 <- linearForward(linear_forward2$Z, params$W3, params$b3)
cat("Shape of Z1: \n", dim(linear_forward1$Z), "\n\n", "linear_cache: \n")
lapply(linear_forward1$cache, function(x) dim(x))
cat("Shape of Z2: \n", dim(linear_forward2$Z), "\n\n", "linear_cache: \n")
lapply(linear_forward2$cache, function(x) dim(x))
cat("Shape of Z3: \n", dim(linear_forward3$Z), "\n\n", "linear_cache: \n")
lapply(linear_forward3$cache, function(x) dim(x))
linearActivationForward <- function(A_prev, W, b, activation) {
linear_forward <- linearForward(A_prev, W, b)
Z <- linear_forward$Z
linear_cache <- linear_forward$cache
if (activation == "sigmoid") {
A <- apply(X = Z, MARGIN = c(1, 2), function(x) sigmoid(x)$A)
activation_cache <- apply(X = Z, MARGIN = c(1, 2), function(x) sigmoid(x)$A)
cache <- list("linear_cache" = linear_cache,
"activation_cache" = activation_cache)
out <- list("A" = A,
"cache" = cache)
return (out)
}
else if (activation == "relu") {
A <- apply(X = Z, MARGIN = c(1, 2), function(x) relu(x)$A)
activation_cache <- apply(X = Z, MARGIN = c(1, 2), function(x) relu(x)$A)
cache <- list("linear_cache" = linear_cache,
"activation_cache" = activation_cache)
out <- list("A" = A,
"cache" = cache)
return (out)
}
}
linear_activation_forward1 <- linearActivationForward(A_prev = X_train, W = params$W1, b = params$b1, activation = "relu")
linear_activation_forward2 <- linearActivationForward(A_prev = linear_activation_forward1$A, W = params$W2, b = params$b2, activation = "relu")
linear_activation_forward3 <- linearActivationForward(A_prev = linear_activation_forward2$A, W = params$W3, b = params$b3, activation = "relu")
# linear_activation_forward1
cat("Shape of A1: \n", dim(linear_activation_forward1$A), "\n\n", "Linear Cache: \n")
lapply(linear_activation_forward1$cache$linear_cache, function(x) dim(x))
cat("\nActivation Cache: \n")
dim(linear_activation_forward1$cache$activation_cache)
# linear_activation_forward2
cat("Shape of A2: \n", dim(linear_activation_forward2$A), "\n\n", "Linear Cache: \n")
lapply(linear_activation_forward2$cache$linear_cache, function(x) dim(x))
cat("\nActivation Cache: \n")
dim(linear_activation_forward2$cache$activation_cache)
# linear_activation_forward3
cat("Shape of A3: \n", dim(linear_activation_forward3$A), "\n\n", "Linear Cache: \n")
lapply(linear_activation_forward3$cache$linear_cache, function(x) dim(x))
cat("\nActivation Cache: \n")
dim(linear_activation_forward3$cache$activation_cache)
LModelForward <- function(X, parameters) {
caches = list()
A = X
L = floor(length(parameters)/2)
A_prev <- A
for (i in 1:(L-1)) {
W <- paste("W", i, sep = "")
b <- paste("b", i, sep = "")
linear_activation_forward <- linearActivationForward(A_prev, parameters[[W]], parameters[[b]], activation = "relu")
A <- linear_activation_forward$A
cache <- linear_activation_forward$cache
caches <- append(caches, cache)
A_prev <- A
}
WL <- paste("W", L, sep = "")
bL <- paste("b", L, sep = "")
AL <- linearActivationForward(A_prev, parameters[[WL]], parameters[[bL]], activation = "sigmoid")$A
cache <- linearActivationForward(A_prev, parameters[[WL]], parameters[[bL]], activation = "sigmoid")$cache
caches <- append(caches, cache)
out <- list("AL" = AL,
"caches" = caches)
return (out)
}
L_model_forward <- LModelForward(X_train, params)
L_model_forward$caches
computeCost <- function(AL, y) {
m <- dim(y)[2]
logprobs <- (log(AL) * y) + (log(1-AL) * (1-y))
cost <- -sum(logprobs/m)
return (cost)
}
cost <- computeCost(L_model_forward$AL, y_train)
cost
relu_backward <- function(dA, cache){
Z <- cache
dZ <- as.matrix(dA)
dZ[Z <= 0] <- 0
return (dZ)
}
sigmoid_backward <- function(dA, cache) {
Z <- cache
s <- 1 / (1 + exp(-Z))
dZ <- as.matrix(dA * s * (1-s))
return (dZ)
}
linearBackward <- function(dZ, cache) {
A_prev <- cache$A
W <- cache$W
b <- cache$b
m <- dim(A_prev)[2]
dW <- 1/m * (dZ %*% t(A_prev))
db <- matrix(1/m * sum(dZ), nrow = dim(dW)[1])
dA_prev <- t(W) %*% dZ
out <- list("dA_prev" = dA_prev,
"dW" = dW,
"db" = db)
return (out)
}
dZ <- cost-y_train
linear_backward3 <- linearBackward(dZ, L_model_forward$caches[5]$linear_cache)
linear_backward2 <- linearBackward(linear_backward3$dA_prev, L_model_forward$caches[3]$linear_cache)
linear_backward1 <- linearBackward(linear_backward2$dA_prev, L_model_forward$caches[1]$linear_cache)
cat("dim dZ3: \n")
cat(dim(dZ), "\n\n")
cat("\nLinear Backward 3:\n ")
lapply(linear_backward3, function(x) dim(x))
cat("\nLinear Backward 2: \n")
lapply(linear_backward2, function(x) dim(x))
cat("\nLinear Backward 1: \n")
lapply(linear_backward1, function(x) dim(x))
linearActivationBackward <- function(dA, linear_cache, activation_cache, activation) {
if (activation == "relu") {
dZ <- relu_backward(dA, activation_cache)
}  else if (activation == "sigmoid") {
dZ <- sigmoid_backward(dA, activation_cache)
}
dA_prev <- linearBackward(dZ, linear_cache)$dA_prev
dW <- linearBackward(dZ, linear_cache)$dW
db <- linearBackward(dZ, linear_cache)$db
out <- list("dA_prev" = dA_prev,
"dW" = dW,
"db" = db)
return (out)
}
dA <- apply(X = dZ, MARGIN = c(1, 2), function(x) sigmoid(x)$A)
linear_activation_backward3 <- linearActivationBackward(dA = dA,
linear_cache = L_model_forward$caches[5]$linear_cache,
activation_cache = L_model_forward$caches[6]$activation_cache,
activation = "sigmoid")
linear_activation_backward2 <- linearActivationBackward(dA = linear_activation_backward3$dA_prev,
linear_cache = L_model_forward$caches[3]$linear_cache,
activation_cache = L_model_forward$caches[4]$activation_cache,
activation = "relu")
linear_activation_backward1 <- linearActivationBackward(dA = linear_activation_backward2$dA_prev,
linear_cache = L_model_forward$caches[1]$linear_cache,
activation_cache = L_model_forward$caches[2]$activation_cache,
activation = "relu")
cat("dim dA3: \n", dim(dA), "\n\n")
cat("\nLinear Backward 3:\n ")
lapply(linear_activation_backward3, function(x) dim(x))
cat("\nLinear Backward 2:\n ")
lapply(linear_activation_backward2, function(x) dim(x))
cat("\nLinear Backward 1:\n ")
lapply(linear_activation_backward1, function(x) dim(x))
LModelBackward <- function(AL, Y, caches) {
L <- length(caches) - 1
grads <- list()
m <- dim(AL)[2]
dA_L <- -((Y/AL) - ((1 - Y)/(1 - AL)))
current_linear_cache <- caches[L]$linear_cache
current_activation_cache <- caches[L+1]$activation_cache
linear_activation_backward_L <- linearActivationBackward(dA = dA_L,
linear_cache = current_linear_cache,
activation_cache = current_activation_cache,
activation = "sigmoid")
dAL <- paste("dA", floor(L/2)+1, sep="")
dWL <- paste("dW", floor(L/2)+1, sep="")
dbL <- paste("db", floor(L/2)+1, sep="")
grads[[dAL]] <- linear_activation_backward_L$dA_prev
grads[[dWL]] <- linear_activation_backward_L$dW
grads[[dbL]] <- linear_activation_backward_L$db
for (i in seq(L-2, 1, -2)) {
current_linear_cache <- caches[i]$linear_cache
current_activation_cache <- caches[i+1]$activation_cache
linear_activation_backward <- linearActivationBackward(dA = grads[[dAL]],
linear_cache = current_linear_cache,
activation_cache = current_activation_cache,
activation = "relu")
dA_prev_temp <- linear_activation_backward$dA_prev
dW_temp <- linear_activation_backward$dW
db_temp <- linear_activation_backward$db
dAL <- paste("dA", floor(i/2)+1, sep="")
dWL <- paste("dW", floor(i/2)+1, sep="")
dbL <- paste("db", floor(i/2)+1, sep="")
grads[[dAL]] <- dA_prev_temp
grads[[dWL]] <- dW_temp
grads[[dbL]] <- db_temp
}
return(grads)
}
L_model_backward<- LModelBackward(L_model_forward$AL, y_train, L_model_forward$caches)
L_model_backward
updateParameters <- function(parameters, grads, learning_rate){
L = floor(length(parameters)/2)
for (i in 1:L) {
W <- paste("W", i, sep="")
dW <- paste("dW", i, sep="")
b <- paste("b", i, sep="")
db <- paste("db", i, sep="")
parameters[[W]] <- parameters[[W]] - learning_rate * grads[[dW]]
parameters[[b]] <- parameters[[b]] - learning_rate * grads[[db]]
}
return (parameters)
}
update_params <- updateParameters(parameters = params, grads = L_model_backward, learning_rate = 0.1)
update_params
trainModel <- function(X, y, layer_size_list, iterations, learning_rate = 0.01) {
init_params <- initializeParameters(layer_size_list)
cost_history <- c()
for (i in 1:iterations) {
forward_pass <- LModelForward(X, init_params)
cost <- computeCost(forward_pass$AL, y)
backward_pass <- LModelBackward(forward_pass$AL, y, forward_pass$caches)
update_parameters <- updateParameters(init_params, backward_pass, learning_rate = learning_rate)
init_params <- update_parameters
cost_history <- c(cost_history, cost)
cat("Iteration", i, " | Cost: ", cost_history[i], "\n")
}
model_out <- list("updated_params" = update_parameters,
"cost_hist" = cost_history)
return (model_out)
}
train_model <- trainModel(X_train, y_train, list(2, 4, 3, 1), 10, 0.01)
makePrediction <- function(X, layer_size_list){
init_params <- initializeParameters(layer_size_list)
forward_pass <- LModelForward(X, init_params)
pred <- forward_pass$AL
return (pred)
}
y_pred <- makePrediction(X_test, list(2, 3, 4, 1))
y_pred <- round(y_pred)
y_pred
y_test
tb <- table(y_test, y_pred)
tb
acc <- (tb[1] + tb[4])/sum(tb)
cat("We are getting an accuracy of", acc*100, "%.")
